
# Simple Multi‑Agent Chat System

A minimal multi-agent system where a **Coordinator** orchestrates three worker agents:
**Research**, **Analysis**, and **Memory**. It accepts NL questions, decomposes tasks,
persists structured memory, and produces traceable outputs.

## Architecture

- `Coordinator` — routes tasks, does simple complexity analysis, merges results, and logs conversation memory.
- `ResearchAgent` — retrieves facts from a curated mock knowledge base.
- `AnalysisAgent` — ranks & summarizes research outputs via keyword/length heuristics; emits a recommendation.
- `MemoryAgent` — hybrid keyword + vector (bag-of-words cosine) retrieval over persistent memories.
- `MemoryStore` — JSON-backed store with a lightweight vector index (TF-normalized BoW + idf).

Sequence (typical complex query):

1. User query → **Coordinator** (simple planner)
2. **ResearchAgent** (mock search) → facts
3. **AnalysisAgent** (ranking/summary) → synthesis + recommendation
4. **Coordinator** writes conversation, knowledge, and agent_state memories
5. **MemoryAgent** can recall prior items using hybrid search

## Run (Local)

### Python
```bash
cd multi_agent_chat
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python main.py "Research transformer architectures, analyze their computational efficiency, and summarize key trade-offs."
```

### Scenarios (outputs written to `outputs/`)
```bash
python tests/run_scenarios.py
```

### Docker
```bash
docker build -t multi-agent-chat .
docker run --rm -it -v $(pwd)/outputs:/app/outputs multi-agent-chat python tests/run_scenarios.py
```

### Docker Compose
```bash
docker compose up --build
```

## Files

- `main.py` — CLI entrypoint
- `coordinator.py` — planner/controller
- `agents/agents.py` — Research, Analysis, Memory agents
- `memory.py` — structured memory & vector index
- `knowledge_base.py` — mock KB content
- `tests/run_scenarios.py` — generates required sample logs
- `outputs/` — sample outputs generated by tests
- `Dockerfile`, `docker-compose.yaml` — containerization
- `requirements.txt` — minimal dependencies (only stdlib used)

## Memory Design

Each record is structured with: `id`, `kind` (`conversation|knowledge|agent_state`), `topic`, `content`, `source`, `agent`, `confidence`, and `metadata` (with timestamp). Retrieval uses union of keyword match and top‑K vector hits (cosine over normalized TF with idf).

## Graceful Degradation

No online LLM is required. If you wire an LLM later (e.g., Groq free tier), plug it into the `Coordinator._complexity` or an alternate `ResearchAgent`. The system already works without it.

## License

MIT
